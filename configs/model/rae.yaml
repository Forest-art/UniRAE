# @package _global_
# RAE model configuration

_target_: src.models.rae_module.RAELitModule

# RAE configuration
encoder_cls: 'Dinov2withNorm'
encoder_config_path: 'facebook/dinov2-with-registers-base'
encoder_input_size: 224
encoder_params:
  dinov2_path: 'facebook/dinov2-with-registers-base'
  normalize: true

decoder_config_path: 'configs/decoder/ViTXL/decoder_config.json'
decoder_patch_size: 16
pretrained_decoder_path: null
noise_tau: 0.8
reshape_to_2d: true
normalization_stat_path: null

# Training configuration
ema_decay: 0.9978
clip_grad: 0.0

# GAN configuration
disc_weight: 0.75
perceptual_weight: 1.0
disc_start_epoch: 8
disc_upd_start_epoch: 6
lpips_start_epoch: 0
max_d_weight: 10000.0
disc_updates: 1
disc_loss_type: hinge
gen_loss_type: vanilla

# Discriminator architecture
disc_arch:
  dino_ckpt_path: 'models/discs/dino_vit_small_patch8_224.pth'
  ks: 9
  norm_type: 'bn'
  using_spec_norm: true
  recipe: 'S_8'

disc_optimizer:
  lr: 2.0e-4
  betas: [0.9, 0.95]
  weight_decay: 0.0

disc_scheduler:
  type: cosine
  warmup_epochs: 1
  decay_end_epoch: 16
  base_lr: 2.0e-4
  final_lr: 2.0e-5
  warmup_from_zero: true

disc_aug:
  prob: 1.0
  cutout: 0.0

# Image configuration
image_size: 256

# Sampling configuration
sample_every: 2500

# Compile model
compile: false

# Optimizer configuration
optimizer:
  lr: 2.0e-4
  betas: [0.9, 0.95]
  weight_decay: 0.0

scheduler:
  type: cosine
  warmup_epochs: 1
  decay_end_epoch: 16
  base_lr: 2.0e-4
  final_lr: 2.0e-5
  warmup_from_zero: true

# Precision
precision: "fp32"