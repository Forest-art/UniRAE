# @package _global_
# RAE SigLIP experiment configuration
# Using SigLIP2 as encoder with ViT-XL decoder

defaults:
  - override /data: imagenet
  - override /model: rae_siglip
  - override /callbacks: rae
  - override /trainer: default
  - override /logger: tensorboard

# Experiment tags
tags: ["rae", "siglip", "stage1"]

# Random seed
seed: 12345

# Trainer configuration
trainer:
  max_epochs: 16
  precision: 16  # Use mixed precision training (fp16)
  accumulate_grad_batches: 1
  gradient_clip_val: null
  val_check_interval: 1.0
  check_val_every_n_epoch: 1

# Data configuration
data:
  batch_size: 128  # For 4 GPUs: 512/4=128
  num_workers: 8

# Model configuration overrides
model:
  image_size: 224  # Must match encoder_input_size in rae_siglip.yaml (same as DINO v2)
